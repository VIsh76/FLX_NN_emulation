_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Input_1 (InputLayer)         (None, 72, 11)            0         
_________________________________________________________________
Upsampler (Sequential)       (None, 72, 11)            0         
_________________________________________________________________
Sequential_1 (Sequential)    (None, 72, 3)             260369    
=================================================================
Total params: 260,369
Trainable params: 260,369
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Bidir (Bidirectional)        (None, 72, 256)           142336    
_________________________________________________________________
Conv_1 (Conv1D)              (None, 72, 50)            102400    
_________________________________________________________________
activation_1 (Activation)    (None, 72, 50)            0         
_________________________________________________________________
average_pooling1d_1 (Average (None, 72, 50)            0         
_________________________________________________________________
Conv_2 (Conv1D)              (None, 72, 50)            12550     
_________________________________________________________________
activation_2 (Activation)    (None, 72, 50)            0         
_________________________________________________________________
average_pooling1d_2 (Average (None, 72, 50)            0         
_________________________________________________________________
Conv_3 (Conv1D)              (None, 72, 20)            3020      
_________________________________________________________________
activation_3 (Activation)    (None, 72, 20)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 72, 3)             63        
=================================================================
Total params: 260,369
Trainable params: 260,369
Non-trainable params: 0
_________________________________________________________________
emis : type : Normalizer 
fitted : True 
values : (0.9890608787536621, 0.006443938706070185) 
  
o3 : type : Normalizer 
fitted : True 
values : (3.6597821235773154e-06, 4.7702924348413944e-06) 
  
pl : type : Normalizer 
fitted : True 
values : (30594.45703125, 36118.08203125) 
  
q : type : Zero_One 
fitted : True 
values : (0.020224308595061302, 1.8337337924560727e-15) 
  
qi : type : Zero_One 
fitted : True 
values : (0.0010000000474974513, 0.0) 
  
ql : type : Zero_One 
fitted : True 
values : (0.0010000000474974513, 0.0) 
  
ri : type : Zero_One 
fitted : True 
values : (0.00010348010255256668, 1.4999999621068127e-05) 
  
rl : type : Zero_One 
fitted : True 
values : (2.099999983329326e-05, 4.999999873689376e-06) 
  
t : type : Normalizer 
fitted : True 
values : (243.3359832763672, 25.461942672729492) 
  
ts : type : Normalizer 
fitted : True 
values : (283.5641174316406, 6.850484848022461) 
  

o3 : type : Level_Normalizer 
fitted : False 
values : 0 
  
pl : type : Level_Normalizer 
fitted : False 
values : 0 
  

<keras.callbacks.History object at 0x7f2ad899b5f8>
flxu_loss
[[15.778543 ]
 [12.292901 ]
 [11.334481 ]
 [ 6.8603067]
 [10.376828 ]
 [ 9.184454 ]
 [ 7.129053 ]
 [ 8.563654 ]
 [ 5.56807  ]
 [ 5.724469 ]
 [11.214766 ]
 [14.68177  ]
 [ 5.0788374]
 [11.167309 ]
 [ 7.911355 ]
 [ 5.368232 ]
 [10.0075245]
 [12.514979 ]
 [ 3.5148275]
 [ 5.5454245]
 [ 8.442647 ]
 [ 9.954662 ]
 [ 3.5086358]
 [ 6.8519998]
 [ 6.858387 ]
 [ 8.958283 ]
 [11.52693  ]
 [ 8.080201 ]
 [ 3.6703649]
 [ 2.6547234]
 [13.88234  ]
 [10.364507 ]
 [ 7.9895234]
 [ 5.8147554]
 [ 8.379837 ]
 [12.859725 ]
 [10.593336 ]
 [ 5.2144957]
 [ 5.2765493]
 [14.848273 ]
 [14.330758 ]
 [11.276422 ]
 [10.809735 ]
 [11.662386 ]
 [ 6.195918 ]
 [ 7.561599 ]
 [ 5.1819825]
 [ 4.595443 ]
 [ 3.3990633]
 [13.289156 ]
 [ 9.301641 ]
 [ 8.841238 ]
 [ 8.247531 ]
 [ 8.494192 ]
 [11.223043 ]
 [ 9.393494 ]
 [ 6.6429567]
 [ 5.700467 ]
 [ 5.5928774]
 [14.152072 ]
 [15.493059 ]
 [11.218907 ]
 [ 6.646966 ]
 [11.300086 ]
 [10.560988 ]
 [ 8.824938 ]
 [ 8.585725 ]
 [ 6.729661 ]
 [ 6.7000084]]
flxd_loss
[[41.95585  ]
 [33.805653 ]
 [15.254736 ]
 [ 9.114557 ]
 [13.443422 ]
 [17.626657 ]
 [15.368312 ]
 [17.3427   ]
 [15.801988 ]
 [14.5563755]
 [31.947344 ]
 [38.776676 ]
 [13.817199 ]
 [13.4801445]
 [19.783028 ]
 [16.614208 ]
 [16.565353 ]
 [17.905476 ]
 [14.05097  ]
 [16.808151 ]
 [26.035038 ]
 [24.471672 ]
 [ 6.3584523]
 [10.001349 ]
 [ 9.709236 ]
 [ 9.724064 ]
 [15.150101 ]
 [13.323656 ]
 [ 7.964163 ]
 [ 9.0197525]
 [36.06639  ]
 [41.116867 ]
 [13.656653 ]
 [13.426641 ]
 [16.235752 ]
 [22.798807 ]
 [20.571766 ]
 [17.61124  ]
 [16.600536 ]
 [42.41011  ]
 [30.740313 ]
 [14.464693 ]
 [12.723341 ]
 [19.02562  ]
 [13.4500885]
 [17.250336 ]
 [20.373775 ]
 [14.081341 ]
 [ 9.209352 ]
 [32.430798 ]
 [30.77721  ]
 [13.678382 ]
 [13.872205 ]
 [14.317627 ]
 [13.839787 ]
 [15.855701 ]
 [15.657312 ]
 [14.114264 ]
 [15.1364155]
 [33.54964  ]
 [33.701622 ]
 [12.701368 ]
 [15.3518505]
 [17.216825 ]
 [13.811838 ]
 [14.406541 ]
 [15.892509 ]
 [14.844937 ]
 [12.092914 ]]
dfdts_loss
[[33.01506  ]
 [21.438503 ]
 [ 5.1782   ]
 [ 4.302873 ]
 [ 6.8170185]
 [ 4.6391273]
 [12.335384 ]
 [ 9.521243 ]
 [12.232988 ]
 [ 6.830278 ]
 [16.521093 ]
 [10.726391 ]
 [ 5.5615096]
 [ 5.3035536]
 [ 6.125658 ]
 [ 6.0228167]
 [ 6.690236 ]
 [10.034061 ]
 [ 8.578676 ]
 [10.023039 ]
 [13.367946 ]
 [12.540026 ]
 [ 2.0474446]
 [ 2.7998893]
 [ 3.6612911]
 [ 3.4784746]
 [ 8.877943 ]
 [ 8.094638 ]
 [ 5.309766 ]
 [ 4.4557257]
 [20.06662  ]
 [19.171093 ]
 [ 5.2143526]
 [ 4.45082  ]
 [ 4.8321924]
 [ 9.364979 ]
 [ 7.820897 ]
 [ 9.218339 ]
 [ 8.652626 ]
 [19.009052 ]
 [16.67529  ]
 [ 4.004445 ]
 [ 3.6623392]
 [ 6.1443067]
 [ 5.1961107]
 [10.3801365]
 [ 8.859359 ]
 [ 7.88162  ]
 [ 4.79115  ]
 [16.186823 ]
 [16.203522 ]
 [ 4.926609 ]
 [ 5.9225407]
 [ 7.4729633]
 [ 4.967833 ]
 [10.008654 ]
 [ 8.020271 ]
 [ 7.7853127]
 [10.311619 ]
 [15.022623 ]
 [18.607765 ]
 [ 3.465448 ]
 [ 3.8327549]
 [ 5.577139 ]
 [ 5.7054014]
 [14.172703 ]
 [11.84189  ]
 [ 8.163301 ]
 [ 8.387223 ]]
loss
[[90.74945 ]
 [67.537056]
 [31.767416]
 [20.277739]
 [30.637268]
 [31.450237]
 [34.83275 ]
 [35.427597]
 [33.603046]
 [27.111124]
 [59.6832  ]
 [64.18484 ]
 [24.457546]
 [29.951008]
 [33.820045]
 [28.005257]
 [33.26311 ]
 [40.454517]
 [26.144474]
 [32.376614]
 [47.845634]
 [46.96636 ]
 [11.914532]
 [19.653238]
 [20.228914]
 [22.160824]
 [35.554977]
 [29.498495]
 [16.944294]
 [16.1302  ]
 [70.01535 ]
 [70.652466]
 [26.86053 ]
 [23.692217]
 [29.44778 ]
 [45.023506]
 [38.986   ]
 [32.044075]
 [30.529709]
 [76.26744 ]
 [61.746365]
 [29.74556 ]
 [27.195414]
 [36.832314]
 [24.842117]
 [35.192074]
 [34.415115]
 [26.558405]
 [17.399565]
 [61.906776]
 [56.282375]
 [27.446228]
 [28.042276]
 [30.284782]
 [30.030663]
 [35.25785 ]
 [30.32054 ]
 [27.600044]
 [31.040913]
 [62.724335]
 [67.802444]
 [27.385723]
 [25.831573]
 [34.09405 ]
 [30.07823 ]
 [37.404182]
 [36.320126]
 [29.7379  ]
 [27.180145]]
