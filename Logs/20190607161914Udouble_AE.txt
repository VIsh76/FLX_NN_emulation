Seed 0
Optimizer
{'lr': 0.009999999776482582, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 1.0000000116860974e-07, 'epsilon': 1e-07, 'amsgrad': False}
Prepross
emis : type : Normalizer 
fitted : True 
values : (0.9890608787536621, 0.006443938706070185) 
  
o3 : type : Normalizer 
fitted : True 
values : (3.6597821235773154e-06, 4.7702924348413944e-06) 
  
pl : type : Normalizer 
fitted : True 
values : (30594.45703125, 36118.08203125) 
  
q : type : Zero_One 
fitted : True 
values : (0.020224308595061302, 1.8337337924560727e-15) 
  
qi : type : Zero_One 
fitted : True 
values : (0.0010000000474974513, 0.0) 
  
ql : type : Zero_One 
fitted : True 
values : (0.0010000000474974513, 0.0) 
  
ri : type : Zero_One 
fitted : True 
values : (0.00010348010255256668, 1.4999999621068127e-05) 
  
rl : type : Zero_One 
fitted : True 
values : (2.099999983329326e-05, 4.999999873689376e-06) 
  
t : type : Normalizer 
fitted : True 
values : (243.3359832763672, 25.461942672729492) 
  
ts : type : Normalizer 
fitted : True 
values : (283.5641174316406, 6.850484848022461) 
  

type : Prodkernel 
variable : [('pl', 'ts')] 
params :   
  
o3 : type : Level_Normalizer 
fitted : True 
values : [ 1.4804788   0.4821318   0.11851957 -0.01547425 -0.14295265 -0.23479246
 -0.29691094 -0.31512183 -0.30351558 -0.2620851  -0.19202456 -0.09215011
  0.03919216  0.19945498  0.39269057  0.62610805  0.8839508   1.1565665
  1.4465499   1.7168003   1.9577761   2.1296003   2.195062    2.174824
  2.112903    2.011329    1.8483553   1.6040243   1.2977242   0.9796167
  0.67037034  0.36056593  0.07948149 -0.13069114 -0.3062436  -0.44038868
 -0.5411082  -0.601639   -0.6356725  -0.6538687  -0.67315704 -0.6935933
 -0.7162004  -0.7350532  -0.74513334 -0.74891484 -0.7502466  -0.7509676
 -0.7514388  -0.7518485  -0.7522993  -0.7527945  -0.75324535 -0.75366175
 -0.75399345 -0.75425607 -0.75452524 -0.7548009  -0.7550985  -0.75537556
 -0.75558996 -0.7557898  -0.7559986  -0.7562013  -0.7563778  -0.75653315
 -0.75666296 -0.7567747  -0.7568637  -0.7569357  -0.7569986  -0.7570477 ] 
  
pl : type : Level_Normalizer 
fitted : True 
values : [-0.84718525 -0.8471835  -0.8471783  -0.8471025  -0.84709567 -0.8470744
 -0.84706575 -0.846266   -0.84618086 -0.8458507  -0.84573823 -0.8456748
 -0.8452505  -0.844312   -0.8437588  -0.8431921  -0.84180564 -0.8403265
 -0.8392495  -0.8365344  -0.8341324  -0.831573   -0.828089   -0.82375604
 -0.8183974  -0.81250733 -0.80519134 -0.7968752  -0.78698784 -0.7752313
 -0.7611849  -0.7446445  -0.72528976 -0.7031165  -0.6769983  -0.6463301
 -0.6105499  -0.5685686  -0.5195771  -0.4619138  -0.39385307 -0.31405306
 -0.22033495 -0.11036328  0.0168411   0.13606115  0.23885234  0.34159738
  0.44430053  0.5469731   0.6496243   0.7522482   0.8548616   0.9574702
  1.0429602   1.1113509   1.1797415   1.2481173   1.3164907   1.378025
  1.4258908   1.4669111   1.5079386   1.548953    1.5899698   1.6309935
  1.6720208   1.7130393   1.7540516   1.795057    1.8360807   1.8771759 ] 
  
q : type : Level_Normalizer 
fitted : True 
values : [8.2152677e-05 9.8598422e-05 1.2934188e-04 1.5213358e-04 1.6554471e-04
 1.7329167e-04 1.7940841e-04 1.8475619e-04 1.8960217e-04 1.9355322e-04
 1.9637006e-04 1.9797386e-04 1.9789055e-04 1.9487781e-04 1.8943545e-04
 1.8594600e-04 1.8154916e-04 1.7722161e-04 1.7254610e-04 1.6741063e-04
 1.6202951e-04 1.5755052e-04 1.5414733e-04 1.5111461e-04 1.4810851e-04
 1.4511358e-04 1.4249829e-04 1.4032464e-04 1.3860210e-04 1.3720946e-04
 1.3584702e-04 1.3409756e-04 1.3163772e-04 1.2833769e-04 1.2343822e-04
 1.1917829e-04 1.1850417e-04 1.3213471e-04 1.7704058e-04 3.1256120e-04
 6.4787117e-04 1.4066783e-03 3.0062837e-03 6.1117397e-03 1.1345811e-02
 1.7972004e-02 2.5228050e-02 3.4320574e-02 4.5641597e-02 5.8813054e-02
 7.4514292e-02 9.1909789e-02 1.1132440e-01 1.3288863e-01 1.5285519e-01
 1.7087467e-01 1.8951391e-01 2.0974261e-01 2.3303278e-01 2.5722718e-01
 2.7924600e-01 3.0265552e-01 3.2942292e-01 3.5731792e-01 3.8427916e-01
 4.0929383e-01 4.3163055e-01 4.5007375e-01 4.6380609e-01 4.7457761e-01
 4.8509774e-01 4.9903965e-01] 
  

type : Var Supression 
 values : ['pl', 'rl', 'ri', 'ts'] 

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 72, 8)             0         
_________________________________________________________________
up_sampling1d_1 (UpSampling1 (None, 360, 8)            0         
_________________________________________________________________
average_pooling1d_1 (Average (None, 72, 8)             0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Origin_Input (InputLayer)    (None, 72, 8)             0         
_________________________________________________________________
Conv_0 (Conv1D)              (None, 72, 32)            2560      
_________________________________________________________________
leakyrelu_0 (LeakyReLU)      (None, 72, 32)            0         
_________________________________________________________________
Conv_1 (Conv1D)              (None, 72, 64)            20480     
_________________________________________________________________
leakyrelu_1 (LeakyReLU)      (None, 72, 64)            0         
_________________________________________________________________
Conv_2 (Conv1D)              (None, 72, 64)            20480     
_________________________________________________________________
leakyrelu_2 (LeakyReLU)      (None, 72, 64)            0         
_________________________________________________________________
Conv_3 (Conv1D)              (None, 72, 128)           40960     
_________________________________________________________________
leakyrelu_3 (LeakyReLU)      (None, 72, 128)           0         
_________________________________________________________________
AVG_100 (MaxPooling1D)       (None, 36, 128)           0         
_________________________________________________________________
Conv_100 (Conv1D)            (None, 36, 30)            7710      
_________________________________________________________________
relu_100 (Activation)        (None, 36, 30)            0         
_________________________________________________________________
Conv_110 (Conv1D)            (None, 36, 30)            4530      
_________________________________________________________________
relu_110 (Activation)        (None, 36, 30)            0         
_________________________________________________________________
AVG_101 (MaxPooling1D)       (None, 18, 30)            0         
_________________________________________________________________
Conv_101 (Conv1D)            (None, 18, 50)            3050      
_________________________________________________________________
relu_101 (Activation)        (None, 18, 50)            0         
_________________________________________________________________
Conv_111 (Conv1D)            (None, 18, 50)            12550     
_________________________________________________________________
relu_111 (Activation)        (None, 18, 50)            0         
_________________________________________________________________
AVG_102 (MaxPooling1D)       (None, 9, 50)             0         
_________________________________________________________________
Conv_102 (Conv1D)            (None, 9, 128)            12928     
_________________________________________________________________
relu_102 (Activation)        (None, 9, 128)            0         
_________________________________________________________________
Conv_112 (Conv1D)            (None, 9, 150)            76950     
_________________________________________________________________
relu_112 (Activation)        (None, 9, 150)            0         
_________________________________________________________________
Flatten (Flatten)            (None, 1350)              0         
_________________________________________________________________
Dense_0 (Dense)              (None, 540)               729540    
_________________________________________________________________
relu_d_0 (Activation)        (None, 540)               0         
_________________________________________________________________
Dense_1 (Dense)              (None, 450)               243450    
_________________________________________________________________
relu_d_1 (Activation)        (None, 450)               0         
_________________________________________________________________
Dense_2 (Dense)              (None, 360)               162360    
_________________________________________________________________
relu_d_2 (Activation)        (None, 360)               0         
_________________________________________________________________
Reshape (Reshape)            (None, 9, 40)             0         
_________________________________________________________________
Ups_200 (UpSampling1D)       (None, 18, 40)            0         
_________________________________________________________________
Conv_200 (Conv1D)            (None, 18, 150)           18150     
_________________________________________________________________
relu_200 (Activation)        (None, 18, 150)           0         
_________________________________________________________________
Conv_210 (Conv1D)            (None, 18, 100)           60100     
_________________________________________________________________
relu_210 (Activation)        (None, 18, 100)           0         
_________________________________________________________________
Ups_201 (UpSampling1D)       (None, 36, 100)           0         
_________________________________________________________________
Conv_201 (Conv1D)            (None, 36, 128)           38528     
_________________________________________________________________
relu_201 (Activation)        (None, 36, 128)           0         
_________________________________________________________________
Conv_211 (Conv1D)            (None, 36, 128)           82048     
_________________________________________________________________
relu_211 (Activation)        (None, 36, 128)           0         
_________________________________________________________________
Ups_202 (UpSampling1D)       (None, 72, 128)           0         
_________________________________________________________________
Conv_202 (Conv1D)            (None, 72, 256)           98560     
_________________________________________________________________
relu_202 (Activation)        (None, 72, 256)           0         
_________________________________________________________________
Conv_212 (Conv1D)            (None, 72, 256)           393472    
_________________________________________________________________
relu_212 (Activation)        (None, 72, 256)           0         
_________________________________________________________________
Conv3_300 (Conv1D)           (None, 72, 150)           384000    
_________________________________________________________________
elu_300 (ELU)                (None, 72, 150)           0         
_________________________________________________________________
Conv3_301 (Conv1D)           (None, 72, 32)            24000     
_________________________________________________________________
elu_301 (ELU)                (None, 72, 32)            0         
_________________________________________________________________
Conv3_302 (Conv1D)           (None, 72, 16)            2560      
_________________________________________________________________
elu_302 (ELU)                (None, 72, 16)            0         
=================================================================
Total params: 2,438,966
Trainable params: 2,438,966
Non-trainable params: 0
_________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input_RC0 (InputLayer)          (None, 16, 72)       0                                            
__________________________________________________________________________________________________
Last_flatten (Flatten)          (None, 1152)         0           Input_RC0[0][0]                  
__________________________________________________________________________________________________
Last_Dense_0 (Dense)            (None, 72)           83016       Last_flatten[0][0]               
__________________________________________________________________________________________________
Last_Dense_1 (Dense)            (None, 72)           83016       Last_flatten[0][0]               
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 72, 1)        0           Last_Dense_0[0][0]               
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 72, 1)        0           Last_Dense_1[0][0]               
__________________________________________________________________________________________________
Last_Concat (Concatenate)       (None, 72, 2)        0           reshape_1[0][0]                  
                                                                 reshape_2[0][0]                  
==================================================================================================
Total params: 166,032
Trainable params: 166,032
Non-trainable params: 0
__________________________________________________________________________________________________


Unet
list_of_filters_unet =  [[32, 64, 64, 128], [30, 30, 50, 50, 128, 150], [60, 50, 40], [150, 100, 128, 128, 256, 256], [150, 32, 16]]
list_of_kernel_unet =  [[10, 10, 5, 5], [2, 5, 2, 5, 2, 4], [], [3, 4, 3, 5, 3, 6], [10, 5, 5]]
list_of_activation_unet =  [['leakyrelu', 'leakyrelu', 'leakyrelu', 'leakyrelu'], ['relu', 'relu', 'relu', 'relu', 'relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu', 'relu', 'relu', 'relu'], ['elu', 'elu', 'elu']]
flxu_loss
[0.0, 6865.5317]
flxd_loss
[0.0, 15959.616]
loss
[0.0, 22515234.0]
