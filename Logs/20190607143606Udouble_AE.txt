Seed 0
Optimizer
{'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 9.999999974752427e-07, 'epsilon': 1e-07, 'amsgrad': False}
Prepross
emis : type : Normalizer 
fitted : True 
values : (0.9890608787536621, 0.006443938706070185) 
  
o3 : type : Normalizer 
fitted : True 
values : (3.6597821235773154e-06, 4.7702924348413944e-06) 
  
pl : type : Normalizer 
fitted : True 
values : (30594.45703125, 36118.08203125) 
  
q : type : Zero_One 
fitted : True 
values : (0.020224308595061302, 1.8337337924560727e-15) 
  
qi : type : Zero_One 
fitted : True 
values : (0.0010000000474974513, 0.0) 
  
ql : type : Zero_One 
fitted : True 
values : (0.0010000000474974513, 0.0) 
  
ri : type : Zero_One 
fitted : True 
values : (0.00010348010255256668, 1.4999999621068127e-05) 
  
rl : type : Zero_One 
fitted : True 
values : (2.099999983329326e-05, 4.999999873689376e-06) 
  
t : type : Normalizer 
fitted : True 
values : (243.3359832763672, 25.461942672729492) 
  
ts : type : Normalizer 
fitted : True 
values : (283.5641174316406, 6.850484848022461) 
  

type : Prodkernel 
variable : [('pl', 'ts')] 
params :   
  
o3 : type : Level_Normalizer 
fitted : True 
values : [ 1.4092003   0.44895905  0.0955549  -0.0349384  -0.15777646 -0.24560498
 -0.30479243 -0.32087043 -0.30784595 -0.26533845 -0.19421113 -0.09357908
  0.03874034  0.19935088  0.39307064  0.6261645   0.88492686  1.1576482
  1.4467663   1.7167604   1.9573766   2.1335218   2.199677    2.1784525
  2.1146088   2.0107138   1.847045    1.6038198   1.2975922   0.9830109
  0.67076224  0.36155635  0.08012357 -0.13255273 -0.3079996  -0.4398684
 -0.5410722  -0.6023497  -0.635807   -0.6535097  -0.67239386 -0.69293106
 -0.71617717 -0.73507285 -0.7450284  -0.7487739  -0.75007296 -0.7507666
 -0.7512526  -0.75169253 -0.752145   -0.75267065 -0.75312376 -0.7535324
 -0.7538822  -0.75417054 -0.75443846 -0.7547266  -0.7550234  -0.7553014
 -0.75552267 -0.75571716 -0.7559286  -0.7561364  -0.75632375 -0.75648767
 -0.7566142  -0.7567198  -0.75680465 -0.756879   -0.75694513 -0.7569944 ] 
  
pl : type : Level_Normalizer 
fitted : True 
values : [-0.8470114  -0.84699416 -0.84694123 -0.8469224  -0.8468535  -0.84676653
 -0.84667975 -0.8465277  -0.84641385 -0.84619    -0.84592855 -0.8455459
 -0.84512705 -0.8445532  -0.8438382  -0.8429999  -0.84188426 -0.84057146
 -0.83888507 -0.8369085  -0.8344548  -0.8314721  -0.82789856 -0.8236578
 -0.8186021  -0.81257325 -0.805415   -0.79687643 -0.78684187 -0.7749228
 -0.7609867  -0.74463385 -0.7254985  -0.70304    -0.6767849  -0.64614946
 -0.61049914 -0.5687579  -0.51966035 -0.46191144 -0.39393035 -0.3140713
 -0.22037771 -0.11046837  0.01663703  0.13574989  0.23844121  0.34108326
  0.44367766  0.5462394   0.6487775   0.75129056  0.85378546  0.95626974
  1.0416592   1.1099684   1.1782755   1.2465737   1.3148685   1.3763341
  1.4241391   1.4651117   1.5060841   1.5470538   1.5880262   1.6290004
  1.6699672   1.7109374   1.7519026   1.7928729   1.8338394   1.8748938 ] 
  
q : type : Level_Normalizer 
fitted : True 
values : [8.2050050e-05 9.8160002e-05 1.2889858e-04 1.5173247e-04 1.6504878e-04
 1.7272600e-04 1.7890036e-04 1.8435006e-04 1.8931579e-04 1.9344829e-04
 1.9641232e-04 1.9805733e-04 1.9798714e-04 1.9488047e-04 1.8942897e-04
 1.8595862e-04 1.8148811e-04 1.7722315e-04 1.7255425e-04 1.6752025e-04
 1.6216747e-04 1.5767584e-04 1.5426298e-04 1.5119690e-04 1.4823962e-04
 1.4524578e-04 1.4263180e-04 1.4048741e-04 1.3874870e-04 1.3734050e-04
 1.3599177e-04 1.3424449e-04 1.3171573e-04 1.2845416e-04 1.2360545e-04
 1.1939286e-04 1.1859415e-04 1.3213730e-04 1.7667894e-04 3.1339581e-04
 6.4988062e-04 1.4064626e-03 3.0191520e-03 6.0399668e-03 1.1189840e-02
 1.7678101e-02 2.5058953e-02 3.4133069e-02 4.5076404e-02 5.7907477e-02
 7.3582336e-02 9.1301888e-02 1.1151190e-01 1.3338363e-01 1.5382035e-01
 1.7197174e-01 1.8976240e-01 2.1001105e-01 2.3272522e-01 2.5609994e-01
 2.7783376e-01 3.0055621e-01 3.2767591e-01 3.5525510e-01 3.8049313e-01
 4.0564233e-01 4.2737132e-01 4.4549865e-01 4.5877716e-01 4.6962789e-01
 4.8050454e-01 4.9449202e-01] 
  

type : Var Supression 
 values : ['pl', 'rl', 'ri', 'ts'] 

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 72, 8)             0         
_________________________________________________________________
up_sampling1d_2 (UpSampling1 (None, 360, 8)            0         
_________________________________________________________________
average_pooling1d_2 (Average (None, 72, 8)             0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Origin_Input (InputLayer)    (None, 72, 8)             0         
_________________________________________________________________
Conv_0 (Conv1D)              (None, 72, 32)            2560      
_________________________________________________________________
leakyrelu_0 (LeakyReLU)      (None, 72, 32)            0         
_________________________________________________________________
Conv_1 (Conv1D)              (None, 72, 64)            20480     
_________________________________________________________________
leakyrelu_1 (LeakyReLU)      (None, 72, 64)            0         
_________________________________________________________________
Conv_2 (Conv1D)              (None, 72, 64)            20480     
_________________________________________________________________
leakyrelu_2 (LeakyReLU)      (None, 72, 64)            0         
_________________________________________________________________
Conv_3 (Conv1D)              (None, 72, 128)           40960     
_________________________________________________________________
leakyrelu_3 (LeakyReLU)      (None, 72, 128)           0         
_________________________________________________________________
AVG_100 (MaxPooling1D)       (None, 36, 128)           0         
_________________________________________________________________
Conv_100 (Conv1D)            (None, 36, 30)            7710      
_________________________________________________________________
relu_100 (Activation)        (None, 36, 30)            0         
_________________________________________________________________
Conv_110 (Conv1D)            (None, 36, 30)            4530      
_________________________________________________________________
relu_110 (Activation)        (None, 36, 30)            0         
_________________________________________________________________
AVG_101 (MaxPooling1D)       (None, 18, 30)            0         
_________________________________________________________________
Conv_101 (Conv1D)            (None, 18, 50)            3050      
_________________________________________________________________
relu_101 (Activation)        (None, 18, 50)            0         
_________________________________________________________________
Conv_111 (Conv1D)            (None, 18, 50)            12550     
_________________________________________________________________
relu_111 (Activation)        (None, 18, 50)            0         
_________________________________________________________________
AVG_102 (MaxPooling1D)       (None, 9, 50)             0         
_________________________________________________________________
Conv_102 (Conv1D)            (None, 9, 128)            12928     
_________________________________________________________________
relu_102 (Activation)        (None, 9, 128)            0         
_________________________________________________________________
Conv_112 (Conv1D)            (None, 9, 128)            65664     
_________________________________________________________________
relu_112 (Activation)        (None, 9, 128)            0         
_________________________________________________________________
Flatten (Flatten)            (None, 1152)              0         
_________________________________________________________________
Dense_0 (Dense)              (None, 540)               622620    
_________________________________________________________________
relu_d_0 (Activation)        (None, 540)               0         
_________________________________________________________________
Dense_1 (Dense)              (None, 450)               243450    
_________________________________________________________________
relu_d_1 (Activation)        (None, 450)               0         
_________________________________________________________________
Dense_2 (Dense)              (None, 360)               162360    
_________________________________________________________________
relu_d_2 (Activation)        (None, 360)               0         
_________________________________________________________________
Reshape (Reshape)            (None, 9, 40)             0         
_________________________________________________________________
Ups_200 (UpSampling1D)       (None, 18, 40)            0         
_________________________________________________________________
Conv_200 (Conv1D)            (None, 18, 64)            7744      
_________________________________________________________________
relu_200 (Activation)        (None, 18, 64)            0         
_________________________________________________________________
Conv_210 (Conv1D)            (None, 18, 64)            16448     
_________________________________________________________________
relu_210 (Activation)        (None, 18, 64)            0         
_________________________________________________________________
Ups_201 (UpSampling1D)       (None, 36, 64)            0         
_________________________________________________________________
Conv_201 (Conv1D)            (None, 36, 128)           24704     
_________________________________________________________________
relu_201 (Activation)        (None, 36, 128)           0         
_________________________________________________________________
Conv_211 (Conv1D)            (None, 36, 128)           82048     
_________________________________________________________________
relu_211 (Activation)        (None, 36, 128)           0         
_________________________________________________________________
Ups_202 (UpSampling1D)       (None, 72, 128)           0         
_________________________________________________________________
Conv_202 (Conv1D)            (None, 72, 128)           49280     
_________________________________________________________________
relu_202 (Activation)        (None, 72, 128)           0         
_________________________________________________________________
Conv_212 (Conv1D)            (None, 72, 128)           98432     
_________________________________________________________________
relu_212 (Activation)        (None, 72, 128)           0         
_________________________________________________________________
Conv3_300 (Conv1D)           (None, 72, 150)           192000    
_________________________________________________________________
elu_300 (ELU)                (None, 72, 150)           0         
_________________________________________________________________
Conv3_301 (Conv1D)           (None, 72, 32)            24000     
_________________________________________________________________
elu_301 (ELU)                (None, 72, 32)            0         
_________________________________________________________________
Conv3_302 (Conv1D)           (None, 72, 10)            1600      
_________________________________________________________________
elu_302 (ELU)                (None, 72, 10)            0         
=================================================================
Total params: 1,715,598
Trainable params: 1,715,598
Non-trainable params: 0
_________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input_RC0 (InputLayer)          (None, 10, 72)       0                                            
__________________________________________________________________________________________________
Last_flatten (Flatten)          (None, 720)          0           Input_RC0[0][0]                  
__________________________________________________________________________________________________
Last_Dense_0 (Dense)            (None, 72)           51912       Last_flatten[0][0]               
__________________________________________________________________________________________________
Last_Dense_1 (Dense)            (None, 72)           51912       Last_flatten[0][0]               
__________________________________________________________________________________________________
reshape_3 (Reshape)             (None, 72, 1)        0           Last_Dense_0[0][0]               
__________________________________________________________________________________________________
reshape_4 (Reshape)             (None, 72, 1)        0           Last_Dense_1[0][0]               
__________________________________________________________________________________________________
Last_Concat (Concatenate)       (None, 72, 2)        0           reshape_3[0][0]                  
                                                                 reshape_4[0][0]                  
==================================================================================================
Total params: 103,824
Trainable params: 103,824
Non-trainable params: 0
__________________________________________________________________________________________________


Unet
list_of_filters_unet =  [[32, 64, 64, 128], [30, 30, 50, 50, 128, 128], [60, 50, 40], [64, 64, 128, 128, 128, 128], [150, 32, 10]]
list_of_kernel_unet =  [[10, 10, 5, 5], [2, 5, 2, 5, 2, 4], [], [3, 4, 3, 5, 3, 6], [10, 5, 5]]
list_of_activation_unet =  [['leakyrelu', 'leakyrelu', 'leakyrelu', 'leakyrelu'], ['relu', 'relu', 'relu', 'relu', 'relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu', 'relu', 'relu', 'relu'], ['elu', 'elu', 'elu']]
flxu_loss
[0.0, 12.323928393454219, 10.628369743441358, 10.275656868891462, 10.088288483796296, 9.803519040959362, 9.733692812821502, 9.524860146604938, 9.652679317772634, 9.610256116576647, 9.491904176311728, 9.461239912872943, 9.497870048868313, 9.383109889403292, 9.287841796875, 9.033107679076647, 9.189985612782921, 9.176360958397634, 9.100919495884774, 9.110939308449074, 8.937304084683642, 9.09448342656893, 9.117039809992283, 8.80442527488426, 8.72633744855967, 8.847331733860596, 2539.3047]
flxd_loss
[0.0, 31.228220244984566, 25.45309084040638, 24.72947008423354, 23.350451308513374, 22.82771106610082, 22.826013133359055, 22.433921280221192, 22.42679398148148, 22.200339988425927, 22.02293314364712, 21.67212215470679, 21.535110034079217, 21.178590374228396, 21.991576646090536, 21.5361529063786, 21.699823575745885, 21.50045211226852, 21.379422662680042, 21.29077650784465, 21.241558561599795, 21.250787680041153, 21.123454780735596, 20.41084547003601, 20.312397521219136, 20.417375980581276, 5710.488]
loss
[0.0, 46.270801183127574, 37.737991898148145, 36.71844055426955, 35.17105918852881, 34.4159352494856, 34.366769547325106, 33.728298611111114, 33.912953317901234, 33.686579700360085, 33.40201220100309, 33.05640954539609, 32.96285847479424, 32.562224713863166, 33.267124003343625, 32.5678409529321, 32.948867107124485, 32.722348813657405, 32.56567684220679, 32.51972214184671, 32.28835318608539, 32.4946188593107, 32.41720116383745, 31.41187829539609, 31.252989969135804, 31.46146195023148, 8872.703]
