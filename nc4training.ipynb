{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING JUPYTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#! conda install -y tqdm\n",
    "from utils import Load_FLX_dict\n",
    "data_folder=\"Data\"\n",
    "model_folder = \"TrainedModels\"\n",
    "log_folder = 'Log'\n",
    "\n",
    "##### Dictionnary\n",
    "D = Load_FLX_dict()\n",
    "##### Kernels\n",
    "Klist = []\n",
    "##### b_size\n",
    "batch_size= 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from preprocess import ProdKernel, FKernel, DictPrepross, Level_Normalizer\n",
    "from utils import Load_FLX_dict, Plot_Batch\n",
    "from generator import Diff_Generator, Up_and_Down_Generator\n",
    "\n",
    "##### Dictionnary\n",
    "D2 = []\n",
    "D2 = [ DictPrepross(['o3','pl'], [Level_Normalizer(False),Level_Normalizer(True)] )]\n",
    "D = [Load_FLX_dict()]\n",
    "##### Kernels\n",
    "Klist = []\n",
    "##### Full Preprocessing :\n",
    "FP = D + D2 + Klist\n",
    "##### b_size\n",
    "batch_size= 64\n",
    "\n",
    "train_generator =  Up_and_Down_Generator(folder=data_folder, batch_size=batch_size, train=True, preprocess_x=FP)\n",
    "validation_generator =  Up_and_Down_Generator(folder=data_folder, batch_size=batch_size, train=False, preprocess_x=FP, custom_b_p_e = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) ARCHITECTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidir RNN followed by fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `AveragePooling1D` call to the Keras 2 API: `AveragePooling1D(7, padding=\"same\", strides=1)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `AveragePooling1D` call to the Keras 2 API: `AveragePooling1D(4, padding=\"same\", strides=1)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Update your `AveragePooling1D` call to the Keras 2 API: `AveragePooling1D(26, padding=\"same\", strides=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 11)            0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 72, 11)            0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 72, 3)             260369    \n",
      "=================================================================\n",
      "Total params: 260,369\n",
      "Trainable params: 260,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 72, 256)           142336    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 72, 50)            102400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 72, 50)            12550     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 72, 20)            3020      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 72, 20)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 72, 3)             63        \n",
      "=================================================================\n",
      "Total params: 260,369\n",
      "Trainable params: 260,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Flatten, Input, TimeDistributed\n",
    "from keras.layers import Conv1D, UpSampling1D, AveragePooling1D, SeparableConv1D\n",
    "from keras import optimizers\n",
    "from keras.layers import Bidirectional\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import keras\n",
    "\n",
    "def one_loss(y_true, y_pred,i ):\n",
    "    E = mean_squared_error(y_true[:,:,0], y_pred[:,:,0])\n",
    "    return E\n",
    "\n",
    "def flxd_loss(y_true, y_pred):\n",
    "    E = mean_squared_error(y_true[:,:,0], y_pred[:,:,0])\n",
    "    return E\n",
    "\n",
    "def flxu_loss(y_true, y_pred):\n",
    "    E = mean_squared_error(y_true[:,:,1], y_pred[:,:,1])\n",
    "    return E\n",
    "\n",
    "def dfdts_loss(y_true, y_pred, coef=50):\n",
    "    E = mean_squared_error(coef*y_true[:,:,2], coef*y_pred[:,:,2])\n",
    "    return E\n",
    "\n",
    "def Total_loss(y_true, y_pred):\n",
    "    E = flxd_loss(y_true, y_pred)\n",
    "    E += flxu_loss(y_true, y_pred)\n",
    "    E += dfdts_loss(y_true, y_pred)\n",
    "    return(E)\n",
    "\n",
    "\n",
    "n_channel = len(train_generator.variables)\n",
    "o_channel = len(train_generator.new_variables_pred)\n",
    "\n",
    "modelbd = Sequential()\n",
    "modelbd.add(Bidirectional(LSTM(128, return_sequences=True, use_bias=False),input_shape=(72, n_channel)))\n",
    "modelbd.add(Conv1D(50, use_bias=False,kernel_size=8 ,padding='same'))\n",
    "modelbd.add(AveragePooling1D(7, padding='same', stride = 1 ))\n",
    "modelbd.add(Activation('relu'))\n",
    "modelbd.add(Conv1D(50, kernel_size=5 ,padding='same'))\n",
    "modelbd.add(AveragePooling1D(4, padding='same', stride = 1 ))\n",
    "modelbd.add(Activation('relu'))\n",
    "modelbd.add(Conv1D(20, kernel_size=3 ,padding='same'))\n",
    "modelbd.add(Activation('relu'))\n",
    "modelbd.add(TimeDistributed(Dense(o_channel)))\n",
    "#modelbd.add(Flatten())\n",
    "\n",
    "M = Sequential()\n",
    "M.add(UpSampling1D(5))\n",
    "M.add(AveragePooling1D(26, padding='same', stride=5 ))\n",
    "newInput = Input(shape=(72,11))\n",
    "newOutputs  = M(newInput)\n",
    "newOutputs2 = modelbd(newOutputs)\n",
    "modelbd2 = keras.Model(newInput, newOutputs2)\n",
    "rmsprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=1.e-5)\n",
    "modelbd2.compile(loss=Total_loss, optimizer=rmsprop,  metrics=[flxd_loss,flxu_loss, dfdts_loss])\n",
    "modelbd2.summary()\n",
    "\n",
    "modelbd.compile(loss='mse', optimizer=rmsprop)\n",
    "prefix = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "archi = \"Bidir\"\n",
    "modelbd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, frequency=1000):\n",
    "        super(LossHistory, self).__init__()\n",
    "        self.frequency=frequency\n",
    "\n",
    "    @property\n",
    "    def loss_name(self):\n",
    "        return(['flxu_loss', 'flxd_loss', 'dfdts_loss', 'loss'])\n",
    "        \n",
    "    \"\"\"Save the history of the loss \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = dict()\n",
    "        for n in self.loss_name:\n",
    "            self.losses[n] = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        #print(logs['batch'])\n",
    "        if(batch%self.frequency==0):\n",
    "            for n in self.loss_name:\n",
    "                self.losses[n].append( logs.get(n))\n",
    "  \n",
    "    def on_train_end(self, logs={}):\n",
    "        for n in self.loss_name:\n",
    "            self.losses[n] = np.array(self.losses[n])\n",
    "\n",
    "LH = LossHistory(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2de4679e0b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                verbose=1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LH' is not defined"
     ]
    }
   ],
   "source": [
    "history = modelbd2.fit_generator(generator=train_generator ,\n",
    "                    validation_data=validation_generator,\n",
    "                             shuffle=False,\n",
    "                               callbacks = [LH],\n",
    "                               epochs=1,\n",
    "                               verbose=1)\n",
    "\n",
    "modelbd.save(  os.path.join(model_folder, prefix+archi+'.h5')  )\n",
    "\n",
    "if(True):\n",
    "    from contextlib import redirect_stdout\n",
    "    with open(os.path.join(log_folder, prefix), 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            modelbd2.summary()\n",
    "            modelbd.summary()\n",
    "            for i in FP:\n",
    "                print(i)\n",
    "            print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f4d604803730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "F = F_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f43fe00d048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f = plt.figure()\n",
    "ax = plt.add_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCT PLOT\n",
    "def Show_triple_diff(y,y0):\n",
    "    j = 50 #np.random.randint(0)\n",
    "    f = plt.figure( figsize=(15,8)   )\n",
    "    ax = plt.subplot(131)\n",
    "    lev= 35\n",
    "    plt.plot(np.flip(y[:,:,0].T[:lev,j]) , np.arange(lev));\n",
    "    plt.plot(np.flip(y0[:,:,0].T[:lev,j]) , np.arange(lev));\n",
    "    ax.legend([\"truth\", \"pred\"])\n",
    "    ax = plt.subplot(132)\n",
    "    plt.plot(np.flip(y[:,:,1].T[:,j]) , np.arange(72));\n",
    "    plt.plot(np.flip(y0[:,:,1].T[:,j]) , np.arange(72));\n",
    "    ax.legend([\"truth\", \"pred\"])\n",
    "    ax = plt.subplot(133)\n",
    "    plt.plot(np.flip(y[:,:,2].T[:,j]) , np.arange(72));\n",
    "    plt.plot(np.flip(y0[:,:,2].T[:,j]) , np.arange(72));\n",
    "    ax.legend([\"truth\", \"pred\"])\n",
    "\n",
    "\n",
    "\n",
    "def Difference(y,y0):\n",
    "#    y_cumsum = np.cumsum(y[i])\n",
    "#    y0_cumsum = np.cumsum(y0)\n",
    "    return(  np.mean(np.square(y-y0)))\n",
    "\n",
    "def Compare(y,y0, i=0):\n",
    "    f=plt.figure( figsize=(15,8), dpi=80)\n",
    "    ax= f.add_subplot(1,2,1)\n",
    "    ax.plot(np.flip(y0[i]), np.arange(len(y0[i]))) \n",
    "    ax.plot(np.flip(y[i]), np.arange(len(y0[i]))) \n",
    "    ax.legend([\"y pred\", 'y truth'])\n",
    "#    ax.title(\"Diff\")\n",
    "    y_cumsum = np.cumsum(y[i])\n",
    "    y0_cumsum = np.cumsum(y0[i])\n",
    "    ax= f.add_subplot(1,2,2)\n",
    "    ax.plot(np.flip(y0_cumsum), np.arange(len(y0[i])))        \n",
    "    ax.plot(np.flip(y_cumsum), np.arange(len(y0[i])))        \n",
    "    ax.legend([\"y pred\", 'y truth'])\n",
    "#    ax.title(\"Cumulative\")\n",
    "    plt.show()\n",
    "\n",
    "def eliminate_var(m,x):\n",
    "    O = []\n",
    "    for i in range(11):\n",
    "        x0= x.copy()\n",
    "        x0*=0\n",
    "        x0[:,:,i]=x[:,:,i]\n",
    "        O.append(modelbd.predict(x0))\n",
    "    return(O)\n",
    "\n",
    "def Plot_Predictions(O, y, header):\n",
    "    f=plt.figure( figsize=(15,10), dpi=80)\n",
    "    for i,y0 in enumerate(O):\n",
    "        ax= f.add_subplot(3,4,i+1)\n",
    "        ax.set_title(header[i])\n",
    "        for b in range(y0.shape[0]):\n",
    "            ax.plot(np.flip(y0[b]), np.arange(len(y0[b])))\n",
    "    ax= f.add_subplot(3,4,12)\n",
    "    ax.set_title('flx')\n",
    "    for b in range(y0.shape[0]):\n",
    "        ax.plot(np.flip(y[b]), np.arange(len(y[b])))\n",
    "\n",
    "def Normal2(x,header):\n",
    "    O1 = []#['fcld', 'q','qi','ql','rl','ri']\n",
    "    N = [ 'pl']\n",
    "    STD = []\n",
    "    STD2 = []\n",
    "    for i, h in enumerate(header):\n",
    "        if h in O1:\n",
    "            x[:,:,i] = np.max(x[:,:,i], axis=1).reshape(x.shape[0],1)\n",
    "        if h in N:\n",
    "            #print(h, np.mean(x[:,:,i], axis=0)[32])\n",
    "            x[:,:,i] -= np.mean(x[:,:,i], axis=0)\n",
    "        if h in STD:\n",
    "            x[:,:,i] /= (x[:,-1,i]+0.000000001).reshape(-1,1)         \n",
    "        if h in STD2:\n",
    "            x[:,:,i] /= (x[:,0,i]+0.000000001).reshape(-1,1)         \n",
    "    return(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECOND ARCHITECTURE :\n",
    "Not tested yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) TRACKS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2 :\n",
    "\n",
    "- FCNN\n",
    "- (with AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL 2 : FCM-Final FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL 2 : U-net :\n",
    "- use regular U-net so all layers affect each other and more stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3 : Bidir-LSTM \n",
    "> Possible alternatives\n",
    "\n",
    "- use two LSTM to show both impact of superior and inferior layer\n",
    "- use attention model over it\n",
    "- use w embeddings before\n",
    "\n",
    "> TD\n",
    "\n",
    "- Read git trez\n",
    "- Read article of Hedge fun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
