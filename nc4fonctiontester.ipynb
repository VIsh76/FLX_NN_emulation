{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "from math import ceil\n",
    "from preprocess import DictPrepross, Zero_One, Normalizer\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "data_folder=\"Data\"\n",
    "class Basic_Generator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Use hdf5 datasets and simply return the desire variables\n",
    "    To create a new Generator simply inherit this one and change '__init__' and __'data_generation\n",
    "    \"\"\"\n",
    "    def __init__(self, folder=data_folder, train=True, batch_size=64, shuffle=True, custom_b_p_e = 0):\n",
    "        # global parameters\n",
    "        self.train = train\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.max_b = custom_b_p_e\n",
    "        # initialisation\n",
    "        self._set_dirs(folder)\n",
    "        self._initialise_parameters()\n",
    "        # idx\n",
    "        self.idx_folder = np.arange(self._nb_dir)\n",
    "        self.idx_file = np.arange(self._div)\n",
    "        self.idx_el = np.arange(self.Xdim*self.Ydim)\n",
    "        self.current_b = 0\n",
    "\n",
    "        self.current_folder = 0\n",
    "        self.current_file = 0\n",
    "        # randomize\n",
    "        self.on_epoch_end()\n",
    "                \n",
    "    def _set_dirs(self, datafolder):\n",
    "        self.List_of_dir = []\n",
    "        folders = os.listdir(datafolder)\n",
    "        folders.sort()\n",
    "        for i in folders:\n",
    "            if os.path.isdir(os.path.join(datafolder,i)):\n",
    "                self.List_of_dir.append(os.path.join(datafolder,i))\n",
    "        if(self.train):  # last folder is used as test\n",
    "            self.List_of_dir = self.List_of_dir[:-1]\n",
    "        else:\n",
    "            self.List_of_dir = self.List_of_dir[:-1]\n",
    "        self._nb_dir = len(self.List_of_dir)\n",
    "        \n",
    "    def _initialise_parameters(self):\n",
    "        \"\"\" load one file to compute variables such as the dimensions, the name of var etc \"\"\"\n",
    "        x, y = self.load_a_couple(self.load_a_path(0,0))\n",
    "        self._div = int(len(os.listdir(self.List_of_dir[0]))/2)\n",
    "        self.variables = x.columns.levels[0]\n",
    "        self.variables_pred = y.columns.levels[0]\n",
    "        self.Xdim = len(x.index.levels[0])\n",
    "        self.Ydim = len(x.index.levels[1])\n",
    "        self.lev = len(x.columns.levels[1])\n",
    "    \n",
    "    def load_a_path(self, id_fold, id_file):\n",
    "        for f in os.listdir(self.List_of_dir[id_fold]):\n",
    "            if '_in' in f and '_'+str(id_file)+'.' in f:\n",
    "                input_path = os.path.join(self.List_of_dir[id_fold], f)\n",
    "            if '_out' in f and '_'+str(id_file)+'.' in f:\n",
    "                output_path = os.path.join(self.List_of_dir[id_fold], f)        \n",
    "        return (input_path, output_path)\n",
    "        \n",
    "    def load_a_couple(self, path):\n",
    "        \"\"\"Load x and y files given by the two values of path\"\"\"\n",
    "        return  pd.read_hdf(path[0], key='s'), pd.read_hdf(path[1], key='s')\n",
    "\n",
    "    @property\n",
    "    def dimensions(self):\n",
    "        d=dict()\n",
    "        d['div'] = (self._div)\n",
    "        d['var'] = len(self.variables)\n",
    "        d['x'] = self.Xdim\n",
    "        d['y'] = self.Ydim\n",
    "        d['lev'] = self.lev\n",
    "        d['dir'] = self._nb_dir\n",
    "        return(d)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'batch per size'\n",
    "        l = int( (self.Xdim * self.Ydim // self.batch_size) * self._div * self._nb_dir)\n",
    "        if (self.max_b > 0):\n",
    "            return(min(self.max_b, l))            \n",
    "        return(l)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.current_b = 0\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.idx_folder)\n",
    "            np.random.shuffle(self.idx_file)\n",
    "            np.random.shuffle(self.idx_el)\n",
    "        self.reload(self.idx_folder[0], self.idx_file[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        folder_id, file_id, el_id  = self.index_to_ids(index)\n",
    "        # use the shuffled indices\n",
    "        folder_id = self.idx_folder[folder_id]\n",
    "        file_id = self.idx_file[file_id]\n",
    "        el_ids = self.idx_el[el_id*self.batch_size + np.arange(self.batch_size)]\n",
    "        return( self.__data_generation(folder_id, file_id, el_ids))\n",
    "                \n",
    "    def index_to_ids(self,index):\n",
    "        index0 = index\n",
    "        batch_per_file = (self.Xdim*self.Ydim // self.batch_size) \n",
    "        el_id = index0 % batch_per_file \n",
    "        index0 = index0 // batch_per_file\n",
    "        file_id = index0 % self._div\n",
    "        folder_id   = index0 // self._div\n",
    "        return folder_id, file_id, el_id\n",
    "\n",
    "    def reload(self,folder_id, file_id):\n",
    "        \"\"\" Files are only loaded when the id of the file or folder is changed, this mutiply the speed by about 400\"\"\"\n",
    "        if folder_id != self.current_folder or file_id != self.current_file:\n",
    "            self.current_folder = folder_id\n",
    "            self.current_file = file_id      \n",
    "            self.X, self.Y = self.load_a_couple(self.load_a_path(self.current_folder, self.current_file))\n",
    "    \n",
    "    def __data_generation(self, folder_id, file_id, el_ids):\n",
    "        'Generates data containing batch_size samples'\n",
    "        self.reload(folder_id, file_id)\n",
    "        X = np.array(self.X.iloc[el_ids]).reshape(self.batch_size, len(self.variables), self.lev)\n",
    "        Y = np.array(self.Y.iloc[el_ids]).reshape(self.batch_size, len(self.variables_pred), self.lev+1)\n",
    "        return X,Y\n",
    "\n",
    "B = Basic_Generator(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Basic_Generator):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19440/19440 [00:12<00:00, 1519.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.794521570205688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "beg = time.time()\n",
    "for x,y in tqdm(B):\n",
    "    pass\n",
    "print(time.time()-beg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "select_folder = np.random.randint(len(List_of_dir))\n",
    "select_element = np.random.randint(div)\n",
    "\n",
    "print(select_folder, select_element)\n",
    "files = os.listdir(List_of_dir[select_folder])\n",
    "for f in files:\n",
    "    if '_in' in f and str(select_element)+'.' in f:\n",
    "        input_path = os.path.join(List_of_dir[select_folder], f)\n",
    "    if '_out' in f and str(select_element)+'.' in f:\n",
    "        output_path = os.path.join(List_of_dir[select_folder], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_hdf(input_path, key='s')\n",
    "y = pd.read_hdf(output_path, key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 1]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Preprocess(object):\n",
    "    \"\"\"\n",
    "    Parent class of Preprocessing class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.fitted=False\n",
    "        pass\n",
    "\n",
    "    def apply(self,x):\n",
    "        return x\n",
    "\n",
    "    def fit(self,x):\n",
    "        self.fitted=True\n",
    "        return x\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'type : {} \\nfitted : {} \\nvalues : {} \\n  '\n",
    "\n",
    "class Normalizer(Preprocess):\n",
    "    \"\"\"\n",
    "    Transform the input into a variable of mean 0 and norm 1\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m = 0\n",
    "        self.std = 1\n",
    "\n",
    "    def apply(self,x):\n",
    "        x-=self.m\n",
    "        x/=self.std\n",
    "        return x\n",
    "\n",
    "    def fit(self,x):\n",
    "        self.fitted=True\n",
    "        self.m = np.mean(x)\n",
    "        self.std = np.std(x)\n",
    "\n",
    "    def __str__(self):\n",
    "        return super().__str__().format(\"Normalizer\", self.fitted, (self.m, self.std))\n",
    "\n",
    "class Zero_One(Preprocess):\n",
    "    \"\"\"\n",
    "    Match the input to a variable in [0,1]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max=1\n",
    "        self.min=1\n",
    "\n",
    "    def apply(self,x):\n",
    "        x-=self.min\n",
    "        x/=(self.max-self.min)\n",
    "        return x\n",
    "\n",
    "    def fit(self,x):\n",
    "        self.fitted=True\n",
    "        self.min = np.min(x)\n",
    "        self.max = np.max(x)\n",
    "\n",
    "    def __str__(self):\n",
    "        return super().__str__().format(\"Zero_One\", self.fitted, (self.max, self.min))\n",
    "\n",
    "###################################### Dict preprocess class\n",
    "\n",
    "class DictPrepross(object):\n",
    "    \"\"\"\n",
    "    Dictionnary of Preprocess\n",
    "    \"\"\"\n",
    "    def __init__(self, header, functions):\n",
    "        self.dict=dict()\n",
    "        for i,h in enumerate(header):\n",
    "            self.dict[h]=functions[i]\n",
    "\n",
    "    def fitonNetCDF(self, data_in):\n",
    "        for k in self.dict.keys():\n",
    "            self[k].fit(data_in[k][:])\n",
    "\n",
    "    def apply(self,x,h):\n",
    "        if h in self.dict.keys():\n",
    "            return self[h].apply(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        return self.dict[k]\n",
    "\n",
    "    def __str__(self):\n",
    "        out =''\n",
    "        for h in self.dict.keys():\n",
    "            out = out + '{} : {}'.format(h, str(self[h]))+'\\n'\n",
    "        return out\n",
    "\n",
    "################################### KERNEL class\n",
    "\n",
    "class Kernel(object):\n",
    "    def __init__(self, ids):\n",
    "        self.ids = ids\n",
    "\n",
    "    def apply(self, x, header):\n",
    "        return x\n",
    "\n",
    "class ProdKernel(Kernel):\n",
    "    def __init__(self, ids=[]):\n",
    "        Kernel.__init__(self, ids)\n",
    "        self.ids = ids\n",
    "        self.header = []\n",
    "\n",
    "    def apply(self, x, header):\n",
    "        for ids in self.ids:\n",
    "            id1 = np.where(ids[0] == header)[0]\n",
    "            id2 = np.where(ids[1] == header)[0]\n",
    "            k = x[:, :, id1]*x[:, :, id2]\n",
    "            header.append(ids[0]+'*'+ids[1])\n",
    "            x = np.concatenate((k, x), axis=-1)\n",
    "        return x\n",
    "    \n",
    "class FKernel(Kernel):\n",
    "    def __init__(self, func, gamma=1, ids=[]):\n",
    "        Kernel.__init__(self, ids)\n",
    "        self.func = func\n",
    "        self.gamma = gamma\n",
    "        self.fname = str(func).split(' ')[1]\n",
    "        self.ids = ids\n",
    "\n",
    "    def apply(self, x, xheader):\n",
    "        xheader0 = xheader.copy()\n",
    "        self.header = []\n",
    "        for ids in self.ids:\n",
    "            id1 = np.where(ids[0] == xheader)[0]\n",
    "            k = self.func(x[:, :, id1])\n",
    "            xheader0.append(fname+ids[0])\n",
    "            x = np.concatenate((k, x), axis=-1)\n",
    "        self.xheader = xheader\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "HNn = [128,64,16,4] # hidden layer size\n",
    "header = list(x.keys())[6:] # variables are relevant after \"time\"\n",
    "kernels = []\n",
    "testprop = 0.9\n",
    "seed = 0\n",
    "n,p = x['Xdim'].shape[0],x['Ydim'].shape[0]\n",
    "\n",
    "np.random.seed(seed)\n",
    "d = len(header) + np.sum(np.array( [len(k.header) for k in kernels]  ))\n",
    "batch_per_epoch = int(n*p / batch_size)\n",
    "\n",
    "header_dict = [\"ql\",\"qi\",\"q\",\"rl\",\"ri\",\"ts\",\"t\", \"pl\",\"emis\",\"o3\"]  # variable we preprocess\n",
    "fct = [] # how to preprocess them\n",
    "for i in range(5):\n",
    "    fct.append(Zero_One())\n",
    "for j in range(5):\n",
    "    fct.append(Normalizer())\n",
    "    \n",
    "D = DictPrepross(header_dict, fct)\n",
    "del(fct)\n",
    "D.fitonNetCDF(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rnn(x, y, kernels, train_prop=0.9, header=['ql'], batch_size=16, preprocess=DictPrepross([], []),\n",
    "                  maxbatch=-1, loading_prop=0.1, test_data=False):\n",
    "    \"\"\"\"\n",
    "    Generate a batch, randomly for a convolution NN, using only variable in header\n",
    "\n",
    "    x : input data in NetCDF format\n",
    "    y : output data in NetCDF format\n",
    "    kernels : list of kernsl\n",
    "    train_prop : proportion of the training set\n",
    "    header : variable used\n",
    "    lodaing_prop : loaded percentage of the whole data (equilibra between good batches and memory usage)\n",
    "    batch_size : size of the generated batch\n",
    "    preprocess : DictPrepross object to apply to the data\n",
    "    maxbatch : number of batch produced, maxbacth<0 means an infinite number of batch\n",
    "    \"\"\"\n",
    "\n",
    "    maxbatch = int(maxbatch)\n",
    "    n = x['Xdim'].shape[0]\n",
    "    nt = int(n * train_prop)  # id up to training\n",
    "    p = x['Ydim'].shape[0]\n",
    "    lev = x['lev'].shape[0]\n",
    "\n",
    "    x_header = header\n",
    "    x_header.sort()\n",
    "\n",
    "    nbatch = 0\n",
    "    while nbatch != maxbatch:\n",
    "        y_shuffled = np.arange(p)  # Ydim id to be shuffled\n",
    "        # Xdim id but to be shuffled\n",
    "        if test_data:\n",
    "            x_shuffled =  np.arange(n - nt)  # test\n",
    "            x_max = n  # Xdim not to outgrow\n",
    "        else:\n",
    "            x_shuffled = np.arange(nt)  # train\n",
    "            x_max = nt  # Xdim not to outgrow\n",
    "\n",
    "#        np.random.shuffle(y_shuffled) #shuffling y divide the speed by 3\n",
    "        np.random.shuffle(x_shuffled)\n",
    "\n",
    "        id_batches_x = 0  # counting the id for batches coordinates\n",
    "        id_batches_y = 0\n",
    "        while id_batches_x < x_max and nbatch != maxbatch:\n",
    "\n",
    "            nbatch += 1\n",
    "            data_x = np.zeros((batch_size, lev+1, 1))  # batch data\n",
    "            idn = x_shuffled[id_batches_x]  # chosen indice in X_dim\n",
    "            idp = y_shuffled[id_batches_y + np.arange(batch_size)]  # chosen indices in Y_dim\n",
    "\n",
    "            Y = y['flx'][0, :, idp, idn]\n",
    "            Y = Y.swapaxes(0, 1)\n",
    "            for k in x_header:\n",
    "                addvect = np.zeros((batch_size,lev+1, 1))\n",
    "                if len(x[k].shape) == 4:\n",
    "                    a = x[k][:, :, idp, idn]\n",
    "                    a = a.reshape(1, lev, -1)\n",
    "                    a = a.swapaxes(0, 2)\n",
    "                    addvect[:, :-1] = a\n",
    "                    addvect[:,  -1] = addvect[:, -2]\n",
    "                    addvect = preprocess.apply(addvect, k)\n",
    "                elif len(x[k].shape) == 3:\n",
    "                    a = x[k][:, idp, idn]\n",
    "                    a = a.repeat(lev, 1).reshape(1, -1, lev)\n",
    "                    a = a.swapaxes(0, 1)\n",
    "                    a = a.swapaxes(1, 2)\n",
    "                    addvect[:, :-1] = a\n",
    "                    addvect[:,  -1] = addvect[:, -2]\n",
    "                    addvect = preprocess.apply(addvect, k)\n",
    "                    addvect[:, :-1] = 0\n",
    "\n",
    "                data_x = np.concatenate((data_x, addvect), axis=2)\n",
    "            data_x = data_x[:, :, 1:]  # the first channel is full of 0, thus eliminated\n",
    "            for k in kernels:\n",
    "                data_x = k.apply(data_x, x_header)\n",
    "\n",
    "            yield data_x, Y\n",
    "\n",
    "            id_batches_y += batch_size\n",
    "            if id_batches_y + batch_size >= p:\n",
    "                id_batches_y = 0\n",
    "                id_batches_x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator =  lambda Params, batch_size, nb=-1 : generate_rnn( \\\n",
    "                            Params[0], Params[1], kernels=kernels,\\\n",
    "                            train_prop=testprop, header=header,\\\n",
    "                            batch_size = batch_size, maxbatch=nb,  preprocess=D, test_data=False)\n",
    "\n",
    "test_generator = lambda Params, batch_size, nb=1 : generate_rnn( \\\n",
    "                            Params[0], Params[1], kernels=kernels,\\\n",
    "                            train_prop=testprop, header=header,\\\n",
    "                            batch_size = batch_size, maxbatch=nb, preprocess=D, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "listx=[]\n",
    "for xt,yt in train_generator((x,y), 16, nb=5):\n",
    "    listx.append(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = listx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.31797618],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.31797618],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.31797618],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.31797618],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.31797618],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.31797618]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:05,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_generator = lambda Params, batch_size, nb=-1 : generate_conv( \\\n",
    "                            Params[0], Params[1], kernels=kernels,\\\n",
    "                            train_prop=testprop, header=header,\\\n",
    "                            batch_size = batch_size, maxbatch=nb,  preprocess=D)\n",
    "xt, yt = [],[]\n",
    "for x0,y0 in tqdm(batch_generator((x,y), 12, 5)):\n",
    "    xt.append(x0)\n",
    "    yt.append(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ea6cb33e618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'second'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "\n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "tuples\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "index \n",
    "MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],\n",
    "           codes=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]],\n",
    "           names=['first', 'second'])\n",
    "s = pd.Series(np.random.randn(8), index=index)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFnlJREFUeJzt3XuMXGd9xvHnmdldO3ECuS3GTTAOJQRcEAldRaFUtMEEBdrGkYqiRKW4lVULShGIqjQFVaKXP0Ci0FZCbS1CcVsuCYE0LqVAMEnTIhLYkEAuJuRCUhx82UBukNjenfPrH3Nm98xt5+zuXLyvvx9ptef6nt+Z3Xnec86cmXFECACw+lVGXQAAoD8IdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0Aixoa5sTPOOCM2bdo0zE0CwKp3++23PxYRk72WG2qgb9q0SdPT08PcJACserYfKbMcl1wAIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEhEz0C3fa7tOws/T9l+t+3TbN9o+/7896mDKvL6O/bp324tdRsmABy3egZ6RNwXEedFxHmSflnSM5Kul3SVpD0RcY6kPfn4QOy+88e6dvpHg2oeAJKw1EsuWyQ9GBGPSNoqaVc+fZeky/pZGABgaZYa6FdI+kw+vD4i9ufDBySt71tVAIAlKx3otickXSrpc63zIiIkRZf1dtietj09MzOz7EIBAItbyhH6GyV9JyIO5uMHbW+QpPz3oU4rRcTOiJiKiKnJyZ4fFgYAWKalBPqVWrjcIkm7JW3Lh7dJuqFfRQEAlq5UoNteJ+liSV8oTP6gpItt3y/p9fk4AGBESn0eekT8XNLpLdN+ovpdL0NxZDbTDx/7uSqWKrYqFatiqWrLzocrzcMVW86XaQzbHlbJADBUQ/2Ci+VaM1bVfQef1kUfvnnFbc13CLYqlfpwNQ/7SsVtHcR8p9Clg2hMr+Trzw+3bKPSpdNxPq+ar2Nb1Ur7cO828roqK62xvk13Gs7Xq9e1eHtLeRzbamh5zOiEgXJWRaD/+W9t1htf8XxlEcoyqRahiFAWUi1rHs6i8aN8+c7D9TakLCsMR+RtSNE63NZmPp61bK9Q41yWKast1FjL55WtsbhMvY0Ow3ntKbNbOt68QykOz3c0K+h02jugzh1t8Qyx2PG0Tm+tsbgfbXV1qrG102/paBdq7LDP3Wps2c7ij2P3jrZqy60HRC1tYPhWRaCfecoJOvO8M0ddxjEr8lCv5Z1ANHVuXTqdlunL7XTmO9cOHW1rLcUa2+pqrTHfRqPNTh3tQo2Lt7eUGrNMmq1lPdps78DbDgbyfVhsn1PXqaNt62haO50unUTXM9K2TqdzR7to51pZ5GCgY5vtnWOnGov7fPpJE9ryssG/VWdVBDoW58Y/vzgqWk26dbStZ51R6JhaO4l6B9feubS217FzLdHRd+4YQ7W848oK24/W4bJnoVnng5FyNdbXn4ssP8BormthuPmsNsuaz7zbDhRaDigaj+NK/M97L9ILTjuxT/89nRHowIhUKqYTXmU6nt01OqOseDa20Ll+9Z4D+sB/3Ksjc9nA6yPQARwzWo+Ua9nC5atikNayhaPu2vw6C/MaR/3zlxKz5suJjTaLZwA9287PTBqvuy20vXD2NB/o2cLZyoMzPxva40egA4voFjCRNT/Zi9fgm57sLQGTFYKke8Coqc35aYUg6RQwxSBZCMFi22oOvUXbbg0ptdTdaFstwbjQZnOdHbbf4TGIVfzaQuv188Z1+GrF+sXJdXrec9YMvAYCfZVpPeXrFCSLHqkUprcGSeMJVXzSdgqY+eumbUcqiwdM85FS54BpDZL5I6Xieh0Cpm37JQOm+TFpaTvhgGm82FctvEhYrXj+1tfGi5LViheWL6w7MVYptL0wvbnthRcO59st3F3Ure3GdOcvfDa3vXB78XzblYUXO5vbVnNNhenNj0l7290ek/k7pFr39xi5s4dAH4K9+5/S+66/S88erTUfFbUESaeAabwwk3LAVFqeNMsJmLFqRWvH2wNm/kk3gICZX2aJAVMMgn4HDLcOHt8I9CFYO17V5Elr9PThOT07W9Ph2ZqOzGU6Mpvp8FxNzx6tDfwFk4mxitZNVHXixJjWralq3ZoxrZsY04kT9eETJ6o6ac3Y/Pz55fJlTsyXqS4SMMXbwAgYYPgI9CE4+4x12vnWqUWXybLQ0VqmZ4/WdHiupsOzheEO0xqdwOHZWvM6szUdma3lHUc+f7amI/m8x585qv1P1pZ9H/Ta8YrWjle1dqyqEyaqWjNW0QkT9fG144Xh4rTxan2diarWjtXXb0w7YaKiNXlb9XYrebtVOgFgiQj0Y0SlYq2t1ENt0CLqncfh2awp/BtnDws/xWkLncXhDuscmc302M+ONs1rtD23gvt3x6v1I/yxSkVjVWssH65WPD9vvFrJl6lfelmYV9F4frmkvm4lXyaf12n9wnaK8xrtjc23lddRtcZb6mmqtVrcZvt+jOWXbIB+INCPQ7a1Zqx+FKwTxge+vdlaNt8pFDuLxplG8SyiePYxl4VqWaa5WmguC83VGtNCs7X6vNksVKvVP2ahvkx9+Mhsprmsli+bqZblbXRob64W+fxsJO/grFjzQV/smMZaOqL2zqtDR9fSWXTuWNo7pvYOr0vHVNhup46yW4c4lr92gsEi0DFw49WKxqsVnbx21JX0lhWDv9BBNEK/qXPo0JEsdBDF6cXOI/+ddWqvfZ1aFvVOK8vyTqx52WeOzhU6uNBslreX19M0r7CtUVg4C1roIJpCv62Dae04ih1Tcf1CB9TWGTafjXXqmDrVcfq6NTr3+SeP5HFaCQIdKKhUrImKNZF/VUC3D34r3qrZuGMpa7nNstPb75vvuS7culm8o6k4nrW8jT5r2U6H5TvX2VzjbC3T0blMR2uZjs5F/rtWmFb/OdIyXhxeasfQeMPOkfpY3/92/XbLn1ykjacP9q36/UagHyO6hUPTkzhawqJLOCz2ZO8WDmVDqXOdi3+gVvHe77Z2sw51tq4/v//Fx6nlXvq2/Wl/7LKsuebih2gVbyMtPnar+TbRTiodvk+gabzS8sFS+d1K49VK/d7zrsurbXqnT41s3AVVvAOqeDtop4+Mnh8v1Nzp0zSLt7YuZx+Lt4+eeuLEqgtzaZUE+vcPPKX/vm+mLRwWD7ve4bDsQGsLh9YA1ZLbTc3iT5zmT68r3gLZ/gl5rU/wQrsVa7zD7ZHd221df+XBsVg4tLbdK9BaP72v+AmEbbU03YveUlul/ZMIGzVzHTttqyLQP/yVH+hrew92nLeUJ3Gnf/AyT5zGdbzF220NgfLh0Bp280/wkkcVZYOjUyC2PnaLH/EUP8+7MN6hZgDDtyoCvZZl+qVfeI4+//ZfaQslAEBd2S+JPsX2dba/b3uv7VfbPs32jbbvz3+fOshCqxVr7XhVE2MVjVUrhDkAtCgV6JL+TtKXI+Klkl4paa+kqyTtiYhzJO3JxwEAI9Iz0G0/V9JrJV0tSRFxNCKekLRV0q58sV2SLhtUkQCA3socoZ8taUbSP9u+w/bHba+TtD4i9ufLHJA0+C/MAwB0VSbQxyS9StI/RMT5kn6ulssrERGSOt57Z3uH7Wnb0zMzMyutFwDQRZlA3ydpX0Tclo9fp3rAH7S9QZLy34c6rRwROyNiKiKmJicn+1EzAKCDnoEeEQck/cj2ufmkLZLulbRb0rZ82jZJNwykQgBAKWXvQ3+npE/ZnpD0kKTfV70zuNb2dkmPSLp8MCUCAMooFegRcaekTt/QsKW/5QAAlqvsfegAgGMcgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBGlvlPU9sOSnpZUkzQXEVO2T5N0jaRNkh6WdHlEPD6YMgEAvSzlCP2iiDgvIhpfFn2VpD0RcY6kPfk4AGBEVnLJZaukXfnwLkmXrbwcAMBylQ30kPRV27fb3pFPWx8R+/PhA5LW9706AEBppa6hS/rViHjU9vMk3Wj7+8WZERG2o9OKeQewQ5I2bty4omIBAN2VOkKPiEfz34ckXS/pAkkHbW+QpPz3oS7r7oyIqYiYmpyc7E/VAIA2PQPd9jrbJzeGJb1B0t2Sdkvali+2TdINgyoSANBbmUsu6yVdb7ux/Kcj4su2vy3pWtvbJT0i6fLBlQkA6KVnoEfEQ5Je2WH6TyRtGURRAICl452iAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCJKB7rtqu07bH8xHz/b9m22H7B9je2JwZUJAOhlKUfo75K0tzD+IUkfjYgXS3pc0vZ+FgYAWJpSgW77LEm/Ienj+bglvU7SdfkiuyRdNogCAQDllD1C/1tJ75WU5eOnS3oiIuby8X2SzuxzbQCAJegZ6LZ/U9KhiLh9ORuwvcP2tO3pmZmZ5TQBACihzBH6ayRdavthSZ9V/VLL30k6xfZYvsxZkh7ttHJE7IyIqYiYmpyc7EPJAIBOegZ6RPxZRJwVEZskXSHp6xHxO5JukvTmfLFtkm4YWJUAgJ5Wch/6n0p6j+0HVL+mfnV/SgIALMdY70UWRMTNkm7Ohx+SdEH/SwIALAfvFAWARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQAS0TPQba+1/S3b37V9j+2/yKefbfs22w/Yvsb2xODLBQB0U+YI/Yik10XEKyWdJ+kS2xdK+pCkj0bEiyU9Lmn74MoEAPTSM9Cj7mf56Hj+E5JeJ+m6fPouSZcNpEIAQCmlrqHbrtq+U9IhSTdKelDSExExly+yT9KZXdbdYXva9vTMzEw/agYAdFAq0COiFhHnSTpL0gWSXlp2AxGxMyKmImJqcnJymWUCAHpZ0l0uEfGEpJskvVrSKbbH8llnSXq0z7UBAJagzF0uk7ZPyYdPkHSxpL2qB/ub88W2SbphUEUCAHob672INkjaZbuqegdwbUR80fa9kj5r+68l3SHp6gHWCQDooWegR8T3JJ3fYfpDql9PBwAcA3inKAAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJCInoFu+wW2b7J9r+17bL8rn36a7Rtt35//PnXw5QIAuilzhD4n6Y8jYrOkCyW9w/ZmSVdJ2hMR50jak48DAEakZ6BHxP6I+E4+/LSkvZLOlLRV0q58sV2SLhtUkQCA3pZ0Dd32JknnS7pN0vqI2J/POiBpfZd1dtietj09MzOzglIBAIspHei2T5L0eUnvjoinivMiIiRFp/UiYmdETEXE1OTk5IqKBQB0VyrQbY+rHuafiogv5JMP2t6Qz98g6dBgSgQAlFHmLhdLulrS3oj4SGHWbknb8uFtkm7of3kAgLLGSizzGkm/K+ku23fm094n6YOSrrW9XdIjki4fTIkAgDJ6BnpE/K8kd5m9pb/lAACWi3eKAkAiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIRJkvif6E7UO27y5MO832jbbvz3+fOtgyAQC9lDlC/6SkS1qmXSVpT0ScI2lPPg4AGKGegR4Rt0j6acvkrZJ25cO7JF3W57oAAEu03Gvo6yNifz58QNL6PtUDAFimFb8oGhEhKbrNt73D9rTt6ZmZmZVuDgDQxXID/aDtDZKU/z7UbcGI2BkRUxExNTk5uczNAQB6WW6g75a0LR/eJumG/pQDAFiuMrctfkbSNyWda3uf7e2SPijpYtv3S3p9Pg4AGKGxXgtExJVdZm3pcy0AgBXgnaIAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIlYU6LYvsX2f7QdsX9WvogAAS7fsQLddlfQxSW+UtFnSlbY396swAMDSrOQI/QJJD0TEQxFxVNJnJW3tT1kAgKVaSaCfKelHhfF9+TQAwAiMDXoDtndI2iFJGzduXFYbU5tO09OH5/pZFgAkZyWB/qikFxTGz8qnNYmInZJ2StLU1FQsZ0PvuOjFy1kNAI4rK7nk8m1J59g+2/aEpCsk7e5PWQCApVr2EXpEzNn+I0lfkVSV9ImIuKdvlQEAlmRF19Aj4kuSvtSnWgAAK8A7RQEgEQQ6ACSCQAeARBDoAJAIAh0AEuGIZb3XZ3kbs2ckPbLM1c+Q9Fgfy1kN2OfjA/ucvpXu7wsjYrLXQkMN9JWwPR0RU6OuY5jY5+MD+5y+Ye0vl1wAIBEEOgAkYjUF+s5RFzAC7PPxgX1O31D2d9VcQwcALG41HaEDABZxzAV6ry+etr3G9jX5/Ntsbxp+lf1VYp/fY/te29+zvcf2C0dRZz+V/YJx279tO2yv6jsiyuyv7cvzv/M9tj897Br7rcT/9UbbN9m+I//fftMo6uwn25+wfcj23V3m2/bf54/J92y/qq8FRMQx86P6x/A+KOlFkiYkfVfS5pZl/lDSP+bDV0i6ZtR1D2GfL5J0Yj789uNhn/PlTpZ0i6RbJU2Nuu4B/43PkXSHpFPz8eeNuu4h7PNOSW/PhzdLenjUdfdhv18r6VWS7u4y/02S/kuSJV0o6bZ+bv9YO0Iv88XTWyXtyoevk7TFtodYY7/13OeIuCkinslHb1X926FWs7JfMP5Xkj4k6fAwixuAMvv7B5I+FhGPS1JEHBpyjf1WZp9D0nPy4edK+vEQ6xuIiLhF0k8XWWSrpH+JulslnWJ7Q7+2f6wFepkvnp5fJiLmJD0p6fShVDcYS/2y7e2q9/CrWc99zk9FXxAR/znMwgakzN/4JZJeYvsbtm+1fcnQqhuMMvv8AUlvsb1P9e9VeOdwShuppT7fl2TgXxKN/rH9FklTkn5t1LUMku2KpI9I+r0RlzJMY6pfdvl11c/AbrH9ioh4YqRVDdaVkj4ZEX9j+9WS/tX2yyMiG3Vhq9WxdoRe5oun55exPab6qdpPhlLdYJT6sm3br5f0fkmXRsSRIdU2KL32+WRJL5d0s+2HVb/WuHsVvzBa5m+8T9LuiJiNiB9K+oHqAb9aldnn7ZKulaSI+Kaktap/5knKSj3fl+tYC/QyXzy9W9K2fPjNkr4e+asNq1TPfbZ9vqR/Uj3MV/u1VanHPkfEkxFxRkRsiohNqr9ucGlETI+m3BUr83/976ofncv2GapfgnlomEX2WZl9/j9JWyTJ9stUD/SZoVY5fLslvTW/2+VCSU9GxP6+tT7qV4W7vAr8A9VfIX9/Pu0vVX9CS/U/+uckPSDpW5JeNOqah7DPX5N0UNKd+c/uUdc86H1uWfZmreK7XEr+ja36ZaZ7Jd0l6YpR1zyEfd4s6Ruq3wFzp6Q3jLrmPuzzZyTtlzSr+lnXdklvk/S2wt/5Y/ljcle//695pygAJOJYu+QCAFgmAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgET8Pzzrv/BDkLlRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(test[2,:,-3], np.arange(72))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
