{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "\n",
    "from math import ceil\n",
    "from netCDF4 import Dataset\n",
    "from preprocess import DictPrepross, Zero_One, Normalizer\n",
    "from generator import Basic_Generator, Preprocessed_Generator\n",
    "\n",
    "data_folder=\"Data\"\n",
    "B = Basic_Generator(data_folder)\n",
    "header_dict = ['rl', 'ri', 'ql', 'qi', 'q', 'ts', 't', 'emis', 'o3', 'pl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET DICTIONNARY :\n",
    "\n",
    "fct = [] # how to preprocess them\n",
    "for i in range(5):\n",
    "    fct.append(Zero_One())\n",
    "for j in range(5):\n",
    "    fct.append(Normalizer())\n",
    "\n",
    "if os.path.isfile('DictPreprocess_fit.hdf5'):\n",
    "    Dhd = pd.read_hdf('DictPreprocess_fit.hdf5', key='s')\n",
    "    D = DictPrepross(header_dict, fct)\n",
    "    D.load_from_pd(Dhd)\n",
    "else:\n",
    "    print(\"Fitting Dict\")\n",
    "    B = Basic_Generator(data_folder)   \n",
    "    xdim, ydim = B.Xdim, B.Ydim\n",
    "    B = Basic_Generator(data_folder, batch_size=xdim*ydim, shuffle=False, )\n",
    "    D = DictPrepross(header_dict, fct)\n",
    "    D.fitonGen(B)\n",
    "    Dhd = D.to_array_save()\n",
    "    Dhd.to_hdf('DictPreprocess_fit.hdf5', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_dict = ['rl', 'ri', 'ql', 'qi', 'q', 'ts', 't', 'emis', 'o3', 'pl']\n",
    "len(header_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Dict\n",
      "['Data/20190331_2200z', 'Data/20190401_0000z']\n",
      "rl\n",
      "ri\n",
      "ql\n",
      "qi\n",
      "q\n",
      "ts\n",
      "t\n",
      "emis\n",
      "o3\n",
      "pl\n",
      "Fitting Dict\n",
      "['Data/20190401_0200z']\n",
      "rl\n",
      "ri\n",
      "ql\n",
      "qi\n",
      "q\n",
      "ts\n",
      "t\n",
      "emis\n",
      "o3\n",
      "pl\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    print(\"Fitting Dict\")\n",
    "    B = Basic_Generator(data_folder, train=True) \n",
    "    print(B.List_of_dir)\n",
    "    xdim, ydim = B.Xdim, B.Ydim\n",
    "    B = Basic_Generator(data_folder, batch_size=xdim*ydim, shuffle=False, )\n",
    "    D = DictPrepross(header_dict, fct)\n",
    "    D.fitonGen(B)\n",
    "    Dhd = D.to_array_save()\n",
    "    Dhd.to_hdf('DictPreprocess_fit.hdf5', key='s')\n",
    "    print(\"Fitting Dict\")\n",
    "    B = Basic_Generator(data_folder, train=False) \n",
    "    print(B.List_of_dir)\n",
    "    xdim, ydim = B.Xdim, B.Ydim\n",
    "    B = Basic_Generator(data_folder, batch_size=xdim*ydim, shuffle=False, )\n",
    "    D = DictPrepross(header_dict, fct)\n",
    "    D.fitonGen(B)\n",
    "    Dhd = D.to_array_save()\n",
    "    Dhd.to_hdf('DictPreprocess_fit_test.hdf5', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dhd = pd.read_hdf('DictPreprocess_fit.hdf5', key='s')\n",
    "D = DictPrepross(header_dict, fct)\n",
    "D.load_from_pd(Dhd)\n",
    "Dhd = pd.read_hdf('DictPreprocess_fit_test.hdf5', key='s')\n",
    "D2 = DictPrepross(header_dict, fct)\n",
    "D2.load_from_pd(Dhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emis : type : Normalizer \n",
      "fitted : True \n",
      "values : (0.9890608787536621, 0.006443938706070185) \n",
      "  \n",
      "o3 : type : Normalizer \n",
      "fitted : True \n",
      "values : (3.6597821235773154e-06, 4.7702924348413944e-06) \n",
      "  \n",
      "pl : type : Normalizer \n",
      "fitted : True \n",
      "values : (30594.45703125, 36118.08203125) \n",
      "  \n",
      "q : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.020224308595061302, 1.8337337924560727e-15) \n",
      "  \n",
      "qi : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.0010000000474974513, 0.0) \n",
      "  \n",
      "ql : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.0010000000474974513, 0.0) \n",
      "  \n",
      "ri : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.00010348010255256668, 1.4999999621068127e-05) \n",
      "  \n",
      "rl : type : Zero_One \n",
      "fitted : True \n",
      "values : (2.099999983329326e-05, 4.999999873689376e-06) \n",
      "  \n",
      "t : type : Normalizer \n",
      "fitted : True \n",
      "values : (243.3359832763672, 25.461942672729492) \n",
      "  \n",
      "ts : type : Normalizer \n",
      "fitted : True \n",
      "values : (283.5641174316406, 6.850484848022461) \n",
      "  \n",
      "\n",
      "emis : type : Normalizer \n",
      "fitted : True \n",
      "values : (0.9890608787536621, 0.006443938706070185) \n",
      "  \n",
      "o3 : type : Normalizer \n",
      "fitted : True \n",
      "values : (3.6597821235773154e-06, 4.7702924348413944e-06) \n",
      "  \n",
      "pl : type : Normalizer \n",
      "fitted : True \n",
      "values : (30594.45703125, 36118.08203125) \n",
      "  \n",
      "q : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.020224308595061302, 1.8337337924560727e-15) \n",
      "  \n",
      "qi : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.0010000000474974513, 0.0) \n",
      "  \n",
      "ql : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.0010000000474974513, 0.0) \n",
      "  \n",
      "ri : type : Zero_One \n",
      "fitted : True \n",
      "values : (0.00010348010255256668, 1.4999999621068127e-05) \n",
      "  \n",
      "rl : type : Zero_One \n",
      "fitted : True \n",
      "values : (2.099999983329326e-05, 4.999999873689376e-06) \n",
      "  \n",
      "t : type : Normalizer \n",
      "fitted : True \n",
      "values : (243.3359832763672, 25.461942672729492) \n",
      "  \n",
      "ts : type : Normalizer \n",
      "fitted : True \n",
      "values : (283.5641174316406, 6.850484848022461) \n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(D)\n",
    "print(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = Preprocessed_Generator(preprocess_x=[D], preprocess_y=[Diff],custom_b_p_e = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "HNn = [128,64,16,4] # hidden layer size\n",
    "header = list(x.keys())[6:] # variables are relevant after \"time\"\n",
    "kernels = []\n",
    "testprop = 0.9\n",
    "seed = 0\n",
    "n,p = x['Xdim'].shape[0],x['Ydim'].shape[0]\n",
    "\n",
    "np.random.seed(seed)\n",
    "d = len(header) + np.sum(np.array( [len(k.header) for k in kernels]  ))\n",
    "batch_per_epoch = int(n*p / batch_size)\n",
    "\n",
    "header_dict = [\"ql\",\"qi\",\"q\",\"rl\",\"ri\",\"ts\",\"t\", \"pl\",\"emis\",\"o3\"]  # variable we preprocess\n",
    "fct = [] # how to preprocess them\n",
    "for i in range(5):\n",
    "    fct.append(Zero_One())\n",
    "for j in range(5):\n",
    "    fct.append(Normalizer())\n",
    "    \n",
    "D = DictPrepross(header_dict, fct)\n",
    "del(fct)\n",
    "D.fitonNetCDF(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator =  lambda Params, batch_size, nb=-1 : generate_rnn( \\\n",
    "                            Params[0], Params[1], kernels=kernels,\\\n",
    "                            train_prop=testprop, header=header,\\\n",
    "                            batch_size = batch_size, maxbatch=nb,  preprocess=D, test_data=False)\n",
    "\n",
    "test_generator = lambda Params, batch_size, nb=1 : generate_rnn( \\\n",
    "                            Params[0], Params[1], kernels=kernels,\\\n",
    "                            train_prop=testprop, header=header,\\\n",
    "                            batch_size = batch_size, maxbatch=nb, preprocess=D, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "select_folder = np.random.randint(len(List_of_dir))\n",
    "select_element = np.random.randint(div)\n",
    "\n",
    "print(select_folder, select_element)\n",
    "files = os.listdir(List_of_dir[select_folder])\n",
    "for f in files:\n",
    "    if '_in' in f and str(select_element)+'.' in f:\n",
    "        input_path = os.path.join(List_of_dir[select_folder], f)\n",
    "    if '_out' in f and str(select_element)+'.' in f:\n",
    "        output_path = os.path.join(List_of_dir[select_folder], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
